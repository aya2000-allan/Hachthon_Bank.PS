# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1siaxfvnhKObC5ayRUrWMa-O15ZLgzzf4
"""

import pandas as pd

# If your CSV file is encoded in UTF-8 (important for Arabic)
df = pd.read_csv(
    'Dataset.csv',
    encoding='utf-8',
    quotechar='"',
    quoting=0,              # quoting=csv.QUOTE_MINIMAL (default, for normal CSVs with quotes)
    skip_blank_lines=True,
    engine='python'         # engine='python' is needed for multi-line quoted fields
)
print(df)
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

# تأكد من أن البيانات اختلطت
print(df.head())

import re

def clean_arabic_text(text):
    text = re.sub(r"\r\n|\n", " ", text)       # Remove newlines
    text = re.sub(r"http\S+", "", text)        # Remove URLs
    text = re.sub(r"\s+", " ", text).strip()   # Remove extra spaces
    text = re.sub(r"[^ء-ي\s]", "", text)       # إزالة الأرقام والرموز
    return text

df['conversation'] = df['conversation'].apply(clean_arabic_text)

def normalize_arabic(text):
    text = re.sub(r"[إأآا]", "ا", text)  # توحيد الألف
    text = re.sub(r"ى", "ي", text)       # توحيد الياء
    text = re.sub(r"ؤ", "و", text)
    text = re.sub(r"ئ", "ي", text)
    text = re.sub(r"ة", "ه", text)       # توحيد التاء المربوطة (أو يمكن تجاهلها)
    text = re.sub(r"ً|ٌ|ٍ|َ|ُ|ِ|ّ|ْ", "", text)  # إزالة التشكيل
    return text
df['conversation'] = df['conversation'].apply(normalize_arabic)

def remove_repeated_letters(text):
    # أي حرف يتكرر أكثر من مرتين يُحول لحرف واحد
    return re.sub(r'(.)\1{2,}', r'\1', text)
df['conversation'] = df['conversation'].apply(remove_repeated_letters)

def remove_emojis(text):
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # وجوه تعبيرية
        "\U0001F300-\U0001F5FF"  # رموز عامة
        "\U0001F680-\U0001F6FF"  # وسائل نقل
        "\U0001F1E0-\U0001F1FF"  # أعلام دول
        "\U00002702-\U000027B0"
        "\U000024C2-\U0001F251"
        "]+",
        flags=re.UNICODE
    )
    return emoji_pattern.sub(r'', text)
df['conversation'] = df['conversation'].apply(remove_emojis)

from sklearn.model_selection import train_test_split

# تحويل النصوص والتسميات إلى قائمة
texts = df['conversation'].tolist()
labels = df['label'].map({'Negative': 0, 'Neutral': 1, 'Positive': 2}).tolist()

# أولًا: قسم البيانات إلى تدريب (70%) و باقي (30%)
train_texts, temp_texts, train_labels, temp_labels = train_test_split(
    texts, labels, test_size=0.3, random_state=42, stratify=labels
)

# ثانيًا: قسم البيانات المتبقية إلى تحقق (15%) واختبار (15%)
# بما أن temp_texts تمثل 30% من البيانات، نأخذ نصفها للتحقق والنصف للاختبار
val_texts, test_texts, val_labels, test_labels = train_test_split(
    temp_texts, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels
)

print(f"Train size: {len(train_texts)}")
print(f"Validation size: {len(val_texts)}")
print(f"Test size: {len(test_texts)}")

!pip install --upgrade transformers
!pip install --upgrade datasets
!pip install --upgrade tokenizers

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from datasets import Dataset
from transformers import TrainingArguments, Trainer

# تحميل MARBERT
model_name = "UBC-NLP/MARBERT"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

# تحويل النصوص إلى تنسيق Dataset
train_dataset = Dataset.from_dict({'text': train_texts, 'label': train_labels})
val_dataset = Dataset.from_dict({'text': val_texts, 'label': val_labels})
test_dataset = Dataset.from_dict({'text': test_texts, 'label': test_labels})
# دالة تحويل للمدخلات
def tokenize(batch):
    return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=128)

train_dataset = train_dataset.map(tokenize, batched=True)
val_dataset = val_dataset.map(tokenize, batched=True)
test_dataset = test_dataset.map(tokenize, batched=True)

# تحديد الأعمدة المهمة فقط
train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])
val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])
test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])

# تحديث pip وتثبيت نسخ متوافقة
!pip install --upgrade pip
!pip install numpy==1.26.4
!pip install transformers==4.40.1 datasets==2.18.0 scikit-learn==1.4.2
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117  # لو تستخدم GPU

!pip install numpy==1.26.4 --quiet
import os
os.kill(os.getpid(), 9)  # لإعادة تشغيل النواة تلقائيًا

from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
from sklearn.metrics import accuracy_score, f1_score, recall_score
import numpy as np

# تعريف دالة حساب المقاييس
def compute_metrics(p):
    preds = np.argmax(p.predictions, axis=1)
    labels = p.label_ids
    acc = accuracy_score(labels, preds)
    f1 = f1_score(labels, preds, average="macro")
    recall_neg = recall_score(labels, preds, labels=[0], average="macro")  # assuming 0 is negative class
    return {"accuracy": acc, "f1": f1, "recall_negative": recall_neg}

# إعدادات التدريب بدون evaluation_strategy
training_args = TrainingArguments(
    output_dir="./results",
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=2,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_steps=10,
    save_strategy="no"   # منع الحفظ التلقائي لأن النسخة قديمة
)

# إنشاء المدرب
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer
)

# بدء التدريب
trainer.train()
test_results = trainer.evaluate(eval_dataset=test_dataset)

print(f"✅ Test Accuracy: {test_results['eval_accuracy']:.4f}")
print(f"✅ Test F1 Score (macro): {test_results['eval_f1']:.4f}")
print(f"✅ Test Recall (Negative class): {test_results['eval_recall_negative']:.4f}")

from transformers import AutoTokenizer, AutoModelForSequenceClassification

model_name = "UBC-NLP/MARBERT"

# تحميل التوكنيزر والموديل
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

# حفظ في مجلد محلي
tokenizer.save_pretrained("./marbert_tokenizer")
model.save_pretrained("./marbert_model")

from datasets import Dataset
import torch
import numpy as np

def predict_texts(texts, model, tokenizer):
    # تنظيف النصوص
    cleaned_texts = []
    for text in texts:
        text = clean_arabic_text(text)
        text = normalize_arabic(text)
        text = remove_repeated_letters(text)
        text = remove_emojis(text)
        cleaned_texts.append(text)

    # إنشاء Dataset مؤقت من النصوص
    new_dataset = Dataset.from_dict({'text': cleaned_texts})

    # تطبيق نفس التوكنيزر المستخدم في التدريب
    def tokenize(batch):
        return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=128)

    new_dataset = new_dataset.map(tokenize, batched=True)

    # تحويل إلى تنسيق torch
    new_dataset = new_dataset.with_format("torch", columns=["input_ids", "attention_mask"])

    # وضع النموذج في وضع التقييم
    model.eval()

    # المرور على كل عنصر والتنبؤ
    for i in range(len(new_dataset)):
        inputs = {key: val.unsqueeze(0) for key, val in new_dataset[i].items()}  # إضافة batch dim

        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.softmax(outputs.logits, dim=1).cpu().numpy()[0]
            pred = np.argmax(probs)

        classes = ["Negative", "Neutral", "Positive"]
        print(f"النص: {cleaned_texts[i]}")
        print(f"🟩 التوقع: {classes[pred]}")
        print("🔢 الاحتمالات:")
        for cls, prob in zip(classes, probs):
            print(f"  {cls}: {prob:.4f}")
        print("-" * 40)

texts_to_test = [
    # إيجابية
    "التجربة كانت رائعة وسأكررها بالتأكيد.",
    "أحببت المنتج جدًا، جودة ممتازة.",
    "شكراً لخدمتكم السريعة والرائعة.",
    "كل شيء كان على ما يرام، أنتم الأفضل!",

    # سلبية
    "للأسف المنتج وصل تالفًا.",
    "خدمة العملاء كانت سيئة جدًا.",
    "لم يتم حل مشكلتي رغم التواصل المتكرر.",
    "الطلب تأخر أسبوعين ولم يتم الاعتذار حتى!",

    # محايدة
    "استلمت الطرد اليوم.",
    "لم أبدأ باستخدام الخدمة بعد.",
    "لا أعلم إن كان المنتج جيدًا أم لا.",
    "وصلني الطرد كما هو موضح بالموقع.",

    # غامضة أو رمادية (لتحدي النموذج)
    "الموظف كان لطيفًا، لكن الخدمة بطيئة.",
    "المنتج جيد لكن ليس كما توقعت.",
    "هناك أشياء جيدة وأشياء سيئة في الخدمة.",
    "أعجبني التغليف ولكن الطعم لم يكن مميزًا.",

    # صيغ غير مباشرة
    "هل هذه هي الخدمة التي تقدمونها؟",
    "أفضل لو كانت الاستجابة أسرع.",
    "ما زلت أنتظر ردكم منذ يومين.",
    "أظن أن هناك مجالًا للتحسين."
]

predict_texts(texts_to_test, model, tokenizer)

from collections import Counter
print(Counter(labels))

